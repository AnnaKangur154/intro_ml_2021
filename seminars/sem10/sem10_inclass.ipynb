{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar 10. Clustering Hands-on practice\n",
    "\n",
    "## Similar password detection\n",
    "In this assignment we will try to detect similar patterns in passwords that people use all over the internet.\n",
    "\n",
    "The input data is a collection of leaked passwords and it can be downloaded from here https://github.com/ignis-sec/Pwdb-Public/tree/master/wordlists\n",
    "\n",
    "The task is to try to describe the data in terms of clustering: what are the groups of passwords that look quite similar or have similar logic behind them?\n",
    "\n",
    "This seminar should be considered as a research: there are no correct answers, no points and no deadlines - just your time and your experiments with clustering algorithms.\n",
    "\n",
    "We suggest to start with the following steps:\n",
    "- download the data\n",
    "- check if your favourite password is in the database\n",
    "- build a distance matrix using Levenstein distance\n",
    "- apply DBSCAN\n",
    "- apply Agglomerative clustering and examine the dendrogram\n",
    "- experiment with hyperparameters and the distance function\n",
    "- look for more dependencies and password patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from pylev import levenshtein\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_1M = []\n",
    "with open(\"data/ignis-1M.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        words_1M.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_1K = []\n",
    "with open(\"data/ignis-1K.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        words_1K.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array(words_1M[:1000]).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's precompute a matrix of pairwise distances between words. Currently we will be using the Levenstein distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pylev import levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((words.shape[0], words.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here: Fill matrix with distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize it if you'd like to\n",
    "plt.imshow(X, cmap=\"Purples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = # DBSCAN params\n",
    "min_samples = # DBSCAT params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit DBSCAN and collect predicated labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(#\n",
    "labels = db.labels_\n",
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the clusters:\n",
    "- how many clusters are there?\n",
    "- what are there sizes?\n",
    "- are there any meaningful clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have to condense the distance matrix using `pdist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_X = pdist(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose your type of linkage and cluster the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage = hierarchy.linkage(# YOUR CODE HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to the shape of `linkage` - read the manual. You can write soem code to analyze the `linkage` and track the order how objects were merged into clusters.\n",
    "\n",
    "Plot the dendrogram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "dn = hierarchy.dendrogram(linkage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to do the agglomerative clustering. \n",
    "\n",
    "Try to apply it and investigate the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(# YOUR CODE HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to be creative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creativity challenge #1: Imporved Levenstein Distance\n",
    "\n",
    "We may consider some operations to be less expensive than the others. To imply these ideas we could use a custom weighted Levenstein Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U strsimpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strsimpy.weighted_levenshtein import WeightedLevenshtein\n",
    "\n",
    "\n",
    "def insertion_cost(char):\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def deletion_cost(char):\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def substitution_cost(char_a, char_b):\n",
    "    if char_a == 't' and char_b == 'r':\n",
    "        return 0.5\n",
    "    return 1.0\n",
    "\n",
    "weighted_levenshtein = WeightedLevenshtein(\n",
    "    substitution_cost_fn=substitution_cost,\n",
    "    insertion_cost_fn=insertion_cost,\n",
    "    deletion_cost_fn=deletion_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weighted_levenshtein.distance('Stting1', 'String1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weighted_levenshtein.distance('String1', 'Stting1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creativity challenge #2: Kmeans\n",
    "\n",
    "Invent a method how to apply Kmeans to this tasks. \n",
    "Spoiler: you will have to map the words into some linear space.\n",
    "\n",
    "*Tip*: after you are done with clustering, use `PCA(k=2)` or `PCA(k=3)` to visualize your clusters in 2-d or 3-d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
